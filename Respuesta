
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2


# DATASET (Ejemplo: usar directorio local o Colab dataset)

# Supongamos que tenemos un dataset en carpetas 'train/' y 'val/' con subcarpetas por clase
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    'train/',
    target_size=(128,128),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    'val/',
    target_size=(128,128),
    batch_size=32,
    class_mode='categorical'
)

num_classes = len(train_generator.class_indices)


# ARQUITECTURA 1: CNN Simple

model_cnn1 = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D(2,2),
    BatchNormalization(),
    
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    BatchNormalization(),
    
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    BatchNormalization(),
    
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

model_cnn1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


# ARQUITECTURA 2: CNN Más Profunda

model_cnn2 = Sequential([
    Conv2D(64, (3,3), activation='relu', input_shape=(128,128,3)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    BatchNormalization(),
    
    Conv2D(128, (3,3), activation='relu'),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    BatchNormalization(),
    
    Conv2D(256, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    BatchNormalization(),
    
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

model_cnn2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


# ARQUITECTURA 3: TRANSFER LEARNING (VGG16)

base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128,128,3))
base_model.trainable = False  # congelar pesos

model_vgg = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

model_vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


# ENTRENAMIENTO

history_cnn1 = model_cnn1.fit(train_generator, validation_data=val_generator, epochs=20)
history_cnn2 = model_cnn2.fit(train_generator, validation_data=val_generator, epochs=20)
history_vgg = model_vgg.fit(train_generator, validation_data=val_generator, epochs=20)

# VISUALIZACIÓN DE RESULTADOS

def plot_history(histories, names):
    plt.figure(figsize=(16,5))
    for i, history in enumerate(histories):
        plt.subplot(1,2,1)
        plt.plot(history.history['accuracy'], label=f'{names[i]} Train')
        plt.plot(history.history['val_accuracy'], label=f'{names[i]} Val')
        plt.title('Accuracy')
        plt.legend()
        
        plt.subplot(1,2,2)
        plt.plot(history.history['loss'], label=f'{names[i]} Train')
        plt.plot(history.history['val_loss'], label=f'{names[i]} Val')
        plt.title('Loss')
        plt.legend()
    plt.show()

plot_history([history_cnn1, history_cnn2, history_vgg], ['CNN1','CNN2','VGG16'])


# CONCLUSIONES 

from IPython.display import Markdown as md

md("""
# Conclusiones sobre la comparación de arquitecturas

- CNN1: Modelo más simple, rápido de entrenar, buena precisión inicial pero limitado en capacidad de generalización.
- CNN2: Modelo más profundo, mejor capacidad de extracción de características, mayor tiempo de entrenamiento pero generalmente más preciso.
- VGG16 Transfer Learning: Mejor rendimiento en general debido a pesos preentrenados, especialmente útil si el dataset es pequeño o moderado.

Mejor arquitectura: Transfer Learning con VGG16, por su capacidad de aprovechar características aprendidas de datasets grandes.  

Mejoras posibles:
- Ajuste fino (unfreeze capas superiores) de la VGG16 para dataset específico.
- Optimización de hiperparámetros: learning rate, batch size.
- Regularización adicional (L2) y técnicas de augmentación más agresivas.
""")
